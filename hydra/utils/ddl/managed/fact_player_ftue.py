# Databricks notebook source
# MAGIC %run ../table_functions

# COMMAND ----------

def create_fact_player_ftue(spark, database,view_mapping, properties={}):
    """
    Create the fact_player_transaction table in the specified environment.

    This function constructs a SQL command to create the fact_player_transaction 
    table with predefined columns and executes it using the create_table function.
    create_table and environment are initiated as part of the table_functions

    Parameters:
    Input
        spark (SparkSession): The Spark session for executing the SQL command.
        title (str): The base title for the table (e.g., the database name).
        properties (dict, optional): A dictionary of properties to add to the table.
    Output
        A checkpoint location should be used for your checkpoint location.

    Example:
    Running it in a dev workspace
    create_fact_player_transaction(spark, 'wwe2k25', {'delta.enableIcebergCompatV2': 'true'})
    Output:  "dbfs:/tmp/wwe2k25/intermediate/streaming/run_dev/fact_player_transaction"
    """

    sql = f"""
            CREATE TABLE IF NOT EXISTS {database}{environment}.managed.fact_player_ftue (
                player_id string  comment 'player identifier from the source',
                platform string  comment 'transformed platform value which can be used for reporting',
                service string  comment 'transformed service value which can be used for reporting',
                step int  comment 'step number',
                step_name string comment 'step name',
                status string comment 'step status',
                config_1 string comment 'extra config',
                date date  comment 'event data',
                dw_insert_ts timestamp comment 'data warehouse audit field for records inserted timestamp',
                dw_update_ts timestamp comment 'data warehouse audit field for records updated timestamp',
                merge_key string comment 'unique id generated by the hash of the grain of the table '
            )
            comment 'player level ftue table'
            partitioned by (platform,date)
    """
    create_table(spark, sql, properties)
    create_fact_player_ftue_view(spark, database, view_mapping)
    return f"dbfs:/tmp/{database}/managed/batch/run{environment}/fact_player_ftue"


# COMMAND ----------

def create_fact_player_ftue_view(spark, database, mapping):
    """
    Create the fact_player_igc_earn_nrt view in the specified environment.

    Parameters:
        spark (SparkSession): The Spark session for executing the SQL command.
        database (str): The database to create the view in.
        mapping (dict): A dictionary of column mappings.
    """
    sql = f"""
    CREATE OR REPLACE VIEW {database}{environment}.managed_view.fact_player_ftue AS (
        SELECT
            player_id,
            platform,
            service,
            step, 
            step_name,
            {','.join(str(mapping[key]) for key in mapping)},
            status,
            date, 
            dw_insert_ts,
            dw_update_ts
        from {database}{environment}.managed.fact_player_ftue
    )
    """
    spark.sql(sql)
