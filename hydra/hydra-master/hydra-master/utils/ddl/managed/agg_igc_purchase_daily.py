# Databricks notebook source
# MAGIC %run ../table_functions

# COMMAND ----------

def create_agg_igc_purchase_daily(spark, database,view_mapping, properties={}):
    """
    Create the fact_player_transaction table in the specified environment.

    This function constructs a SQL command to create the fact_player_transaction 
    table with predefined columns and executes it using the create_table function.
    create_table and environment are initiated as part of the table_functions

    Parameters:
    Input
        spark (SparkSession): The Spark session for executing the SQL command.
        title (str): The base title for the table (e.g., the database name).
        properties (dict, optional): A dictionary of properties to add to the table.
    Output
        A checkpoint location should be used for your checkpoint location.

    Example:
    Running it in a dev workspace
    create_fact_player_transaction(spark, 'wwe2k25', {'delta.enableIcebergCompatV2': 'true'})
    Output:  "dbfs:/tmp/wwe2k25/intermediate/streaming/run_dev/fact_player_transaction"
    """
    
    sql = f"""
            CREATE TABLE IF NOT EXISTS {database}{environment}.managed.agg_igc_purchase_daily 
                    (
                        DATE DATE  COMMENT 'Received date from the source',
                        PLATFORM VARCHAR(16777216)  COMMENT 'Transformed platform value which can be used for reporting',
                        SERVICE VARCHAR(16777216)  COMMENT 'Transformed service value which can be used for reporting',
                        COUNTRY_CODE VARCHAR(16777216)  COMMENT 'Country code from the source',
                        SKU VARCHAR(16777216) NOT NULL,
                        IGC_TYPE VARCHAR(16777216),
                        PLAYER_COUNT_1 decimal(38,0),
                        PLAYER_COUNT_2 decimal(38,0),
                        PLAYER_COUNT_3 decimal(38,0),
                        SKU_COUNT decimal(38,0),
                        IGC_TOTAL_AMOUNT  decimal(38,2),
                        dw_insert_ts timestamp comment 'data warehouse audit field for records inserted timestamp',
                        dw_update_ts timestamp comment 'data warehouse audit field for records updated timestamp',
                        merge_key string comment 'unique id generated by the hash of the grain of the table '
                    )
                    COMMENT 'The table will have Ingame currency purchased aggregated data'
                    partitioned by (date,platform)
        """
    create_table(spark, sql, properties)
    create_agg_igc_purchase_daily_view(spark, database, view_mapping)
    return f"dbfs:/tmp/{database}/managed/streaming/run{environment}/agg_igc_purchase_daily"


# COMMAND ----------

def create_agg_igc_purchase_daily_view(spark, database, mapping):
    """
    Create the fact_player_igc_earn_nrt view in the specified environment.

    Parameters:
        spark (SparkSession): The Spark session for executing the SQL command.
        database (str): The database to create the view in.
        mapping (dict): A dictionary of column mappings.
    """
    sql = f"""
    CREATE VIEW IF NOT EXISTS {database}{environment}.managed_view.agg_igc_purchase_daily AS (
        SELECT
            date,
            platform,
            service,
            country_code,
            sku,
            igc_type,
            {','.join(str(mapping[key]) for key in mapping)},
            sku_count,
            igc_total_amount,
            dw_insert_ts,
            dw_update_ts
        from {database}{environment}.managed.agg_igc_purchase_daily
    )
    """
    spark.sql(sql)
