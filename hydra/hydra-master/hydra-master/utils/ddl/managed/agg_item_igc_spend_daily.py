# Databricks notebook source
# MAGIC %run ../table_functions

# COMMAND ----------

def create_agg_item_igc_spend_daily(spark, database,view_mapping, properties={}):
    """
    Create the fact_player_transaction table in the specified environment.

    This function constructs a SQL command to create the fact_player_transaction 
    table with predefined columns and executes it using the create_table function.
    create_table and environment are initiated as part of the table_functions

    Parameters:
    Input
        spark (SparkSession): The Spark session for executing the SQL command.
        title (str): The base title for the table (e.g., the database name).
        properties (dict, optional): A dictionary of properties to add to the table.
    Output
        A checkpoint location should be used for your checkpoint location.

    Example:
    Running it in a dev workspace
    create_fact_player_transaction(spark, 'wwe2k25', {'delta.enableIcebergCompatV2': 'true'})
    Output:  "dbfs:/tmp/wwe2k25/intermediate/streaming/run_dev/fact_player_transaction"
    """
    
    sql = f"""
            CREATE TABLE IF NOT EXISTS {database}{environment}.managed.agg_item_igc_spend_daily (
                date date  comment 'received date from the source',
                platform string  comment 'transformed platform value which can be used for reporting',
                service string  comment 'transformed service value which can be used for reporting',
                country_code string  comment 'country code from the source',
                game_mode string comment 'mode from the source',
                sub_mode string comment 'submode from the source',
                igc_type string comment 'currency_type from the source',
                item string comment 'item from the source',
                item_type string comment 'item_type from the source',
                player_count decimal(38,0) comment 'player_id from the source',
                igc_type_1_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_1_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_2_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_2_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_3_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_3_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_4_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_4_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_5_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_5_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_6_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_6_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_7_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_7_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_8_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_8_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_9_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_9_spent_amount decimal(38,2) comment 'agg spents placeholder',
                igc_type_10_spent_count decimal(38,0) comment 'agg spents placeholder',
                igc_type_10_spent_amount decimal(38,2) comment 'agg spents placeholder',
                dw_insert_date date comment 'data warehouse audit field for records inserted date',
                dw_insert_ts timestamp comment 'data warehouse audit field for records inserted timestamp',
                dw_update_ts timestamp comment 'data warehouse audit field for records updated timestamp',
                merge_key string comment 'unique id generated by the hash of the grain of the table '
            )
            comment 'the table will have ingame currency spend player level  aggregated data at every 10 mins'
            partitioned by (platform,dw_insert_date)
    """
    create_table(spark, sql, properties)
    create_agg_item_igc_spend_daily_view(spark, database, view_mapping)
    return f"dbfs:/tmp/{database}/managed/streaming/run{environment}/agg_item_igc_spend_daily"


# COMMAND ----------

def create_agg_item_igc_spend_daily_view(spark, database, mapping):
    """
    Create the fact_player_igc_Spend_nrt view in the specified environment.

    Parameters:
        spark (SparkSession): The Spark session for executing the SQL command.
        database (str): The database to create the view in.
        mapping (dict): A dictionary of column mappings.
    """
    sql = f"""
    CREATE OR REPLACE VIEW {database}{environment}.managed_view.agg_item_igc_spend_daily AS (
        SELECT
            date,
            platform,
            service,
            country_code, 
            game_mode,
            sub_mode,
            igc_type,
            item,
            item_type,
            {','.join(str(mapping[key]) for key in mapping)},
            dw_insert_ts,
            dw_update_ts
        from {database}{environment}.managed.agg_item_igc_spend_daily
    )
    """
    spark.sql(sql)