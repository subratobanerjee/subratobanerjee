# Databricks notebook source
# MAGIC %run ../table_functions

# COMMAND ----------

def create_agg_store_interactions_daily(spark, database, view_mapping, properties={}):
    """
    Create the agg_store_interactions_daily table in the specified environment.

    This function constructs a SQL command to create the agg_store_interactions_daily 
    table with predefined columns and executes it using the create_table function.
    create_table and environment are initiated as part of the table_functions

    Parameters:
    Input
        spark (SparkSession): The Spark session for executing the SQL command.
        title (str): The base title for the table (e.g., the database name).
        properties (dict, optional): A dictionary of properties to add to the table.
    Output
        A checkpoint location should be used for your checkpoint location.

    Example:
    Running it in a dev workspace
    agg_store_interactions_daily(spark, 'wwe2k25', {'delta.enableIcebergCompatV2': 'true'})
    Output:  "dbfs:/tmp/wwe2k25/intermediate/streaming/run_dev/agg_store_interactions_daily"
    """
    
    sql = f"""
            CREATE TABLE IF NOT EXISTS {database}{environment}.managed.agg_store_interactions_daily (
                date date comment 'date value from fact_player_store_interaction_daily',
                platform string  comment 'platform value from fact_player_store_interaction_daily',
                service string  comment 'service value from fact_player_store_interaction_daily',
                game_mode string comment 'gamemode value from fact_player_store_interaction_daily',
                sub_mode string comment 'submode value from fact_player_store_interaction_daily',
                store_action string comment 'storeaction value from fact_player_store_interaction_daily',
                item string comment 'itemid value from fact_player_store_interaction_daily',
                item_name string DEFAULT 'Default' comment 'item_name value from fact_player_store_interaction_daily',
                item_type string DEFAULT 'Default' comment 'item_type value from fact_player_store_interaction_daily',
                player_count decimal(38,0) comment 'Count of distinct players',
                time_spent decimal(38,0) comment 'sum of time_spent from fact_player_store_interaction_daily',
                items_purchased decimal(38,0) comment 'sum of numitemspurchased from fact_player_store_interaction_daily',
                items_viewed decimal(38,0) comment 'sum of numitemsviewed from fact_player_store_interaction_daily',
                agg_si_1 decimal(38,0) comment 'dummy null field',
                agg_si_2 decimal(38,0) comment 'dummy null field',
                agg_si_3 decimal(38,0) comment 'dummy null field',
                agg_si_4 decimal(38,0) comment 'dummy null field',
                agg_si_5 decimal(38,0) comment 'dummy null field',
                dw_insert_ts timestamp comment 'data warehouse audit field for records inserted timestamp',
                dw_update_ts timestamp comment 'data warehouse audit field for records updated timestamp',
                merge_key string comment 'unique id generated by the hash of the grain of the table '
            )
            comment 'player store interaction daily table'
            partitioned by (platform,date)
    """
    properties = {
        "delta.feature.allowColumnDefaults": "supported" # this won't work until iceberg v3 is released
    }

    create_table(spark, sql, properties)
    create_agg_store_interactions_daily_view(spark, database, view_mapping)
    return f"dbfs:/tmp/{database}/managed/batch/run{environment}/agg_store_interactions_daily"


# COMMAND ----------

def create_agg_store_interactions_daily_view(spark, database, mapping):
    """
    Create the agg_store_interactions_daily view in the specified environment.

    Parameters:
        spark (SparkSession): The Spark session for executing the SQL command.
        database (str): The database to create the view in.
        mapping (dict): A dictionary of column mappings.
    """
    sql = f"""
    CREATE VIEW IF NOT EXISTS {database}{environment}.managed_view.agg_store_interactions_daily AS (
        SELECT
            date,
            platform,
            service,
            game_mode,
            sub_mode,
            store_action,
            item,
            item_name,
            item_type,
            player_count,
            time_spent,
            items_purchased,
            items_viewed
        from {database}{environment}.managed.agg_store_interactions_daily
    )
    """
    spark.sql(sql)
