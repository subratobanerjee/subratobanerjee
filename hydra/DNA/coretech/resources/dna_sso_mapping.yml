#The main job for raw.
resources:
  jobs:
    dna_sso_mapping_nrt:
      name: dna_sso_mapping_nrt
      max_concurrent_runs: 1

      continuous:
        pause_status: ${var.schedule_status}

      webhook_notifications:
        on_failure:
          - id: ${var.slack_webhook}

      tasks: 

        - task_key: dna_sso_mapping
          job_cluster_key: dna_sso_mapping_nrt_cluster${var.environment}
          notebook_task:
            notebook_path: ../dna_sso_mapping/dna_obfuscated_id_mapping.py
            base_parameters:
              inputParam: '{"environment":"${var.environment}"}'
              checkpoint: 'dbfs:/tmp/inverness/managed/streaming/run${var.environment}/dna_obfuscated_id_mapping'
          webhook_notifications:
            on_failure:
              - id: ${var.slack_webhook} 

         
        

      # The managed cluster will use memory-optimized instances due to having to store state in memory
      job_clusters:
        - job_cluster_key: dna_sso_mapping_nrt_cluster${var.environment}
          new_cluster:
            spark_version: 16.4.x-scala2.12
            data_security_mode: SINGLE_USER
            aws_attributes:
              availability: ON_DEMAND
            node_type_id: m7gd.2xlarge
            driver_node_type_id: m7gd.2xlarge
            num_workers: 2
            init_scripts:
              - workspace: 
                  destination: /Shared/datadog/dd_init.sh
            spark_conf:
              'spark.driver.extraJavaOptions': '-XX:+UseZGC'
            spark_env_vars:
              DD_API_KEY: "{{secrets/data-engineering/dd_api_key}}"
            custom_tags:
              owner: "Data Engineering"
      
      tags:
        business_unit: "Coretech"
        title: "coretech"
        catalog: "reference${var.environment}"
        data_layer: "managed"
        environment: ${var.environment}

      permissions:
        - level: CAN_MANAGE
          group_name: "dna live"
        - level: CAN_MANAGE
          group_name: "data engineering"